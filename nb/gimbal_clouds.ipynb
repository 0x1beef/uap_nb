{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/0x1beef/uap/blob/main/nb/gimbal_clouds.ipynb\">\n",
    "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "<a href=\"https://kaggle.com/kernels/welcome?src=https://github.com/0x1beef/uap/blob/main/nb/gimbal_clouds.ipynb\">\n",
    "    <img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"   />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/0x1beef/uap/main/nb'\n",
    "import urllib.request\n",
    "for py_file in ['utils.py','common.py','opencv_cuda_installer.py']:\n",
    "    urllib.request.urlretrieve(f'{url}/{py_file}', py_file)\n",
    "import utils, common\n",
    "is_main = (__name__ == '__main__')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Download OpenCV built with CUDA support**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opencv_cuda_installer as cv_cuda\n",
    "utils.show_env_info()\n",
    "use_opencv_cuda = %time cv_cuda.install_opencv_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Download the data (center of mass, horizon, video frames)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.download_from_huggingface('logicbear/gimbal/data/object_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(object_data, metadata) = utils.from_parquet_ext('data/object_data.parquet', 'gimbal')\n",
    "center_of_mass = zip(object_data['center_of_mass_x'], object_data['center_of_mass_y'])\n",
    "center_of_mass = [c for c in center_of_mass]\n",
    "human_horizon = object_data['human_horizon']\n",
    "object_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gimbal = common.gimbal_from_huggingface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define a mask that only includes the clouds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def get_height_above_clouds(frame):\n",
    "    time_dist_pairs = [\n",
    "        (0, 25), (2, 30), (4, 30), (6, 30), (8, 50), (10, 45), (12, 40), (14, 55),\n",
    "        (16, 45), (18, 40), (20, 40), (22, 45), (24, 50), (28, 55), (30, 60), (35, 60)\n",
    "    ]\n",
    "    time = gimbal.get_frame_time(frame)\n",
    "    for ((t1,d1),(t2,d2)) in zip(time_dist_pairs, time_dist_pairs[1:]):\n",
    "        if t2 > time:\n",
    "            return d1 + (time - t1) * (d2 - d1) / (t2 - t1)\n",
    "    return 0\n",
    "\n",
    "def unit_vector(angle):\n",
    "    return np.array((math.cos(angle), math.sin(angle)))\n",
    "\n",
    "def get_cloud_top_point_angle(frame, height_offset):\n",
    "    horizon_angle = -math.radians(human_horizon[frame])\n",
    "    height = get_height_above_clouds(frame) + height_offset\n",
    "    com = np.array(center_of_mass[frame])\n",
    "    cloud_top_point = com + unit_vector(horizon_angle + math.pi / 2) * height\n",
    "    return (cloud_top_point, horizon_angle)\n",
    "\n",
    "def get_cloud_top_border_intersections(frame, height_offset, frame_width):\n",
    "    (cloud_top_point, horizon_angle) = get_cloud_top_point_angle(frame, height_offset)\n",
    "    cloud_heading = unit_vector(horizon_angle)\n",
    "    # (x,y) = cloud_top_point + cloud_heading * t\n",
    "    t = lambda x : (x - cloud_top_point[0]) / cloud_heading[0]\n",
    "    y = lambda x : cloud_top_point[1] + cloud_heading[1] * t(x)\n",
    "    return (y(0),y(frame_width-1))\n",
    "\n",
    "flow_masks = [\n",
    "    (0,   373, 115, 427),\n",
    "    (194, 412, 243, 427),\n",
    "    (317, 393, 391, 427),\n",
    "    (369, 256, 426, 323),\n",
    "    (34,  194, 69,  207),\n",
    "    (384, 346, 426, 359),\n",
    "    (413, 318, 426, 386)\n",
    "]\n",
    "def get_full_flow_mask(frame, frame_shape, erode_size):\n",
    "    (h,w) = frame_shape\n",
    "    img_mask = np.full(frame_shape, 255, np.uint8)\n",
    "    # exclude the overlay\n",
    "    for (j0,i0,j1,i1) in flow_masks:\n",
    "        img_mask[i0:i1,j0:j1] = 0\n",
    "    # exclude the border\n",
    "    cv2.rectangle(img_mask, (0,0), (w-1,h-1), color=0, thickness=1)\n",
    "    # exclude everything above the cloud line\n",
    "    (y0,y1) = get_cloud_top_border_intersections(frame, erode_size / 2, w)\n",
    "    points = np.array([[0, 0], [w-1, 0], [w-1, int(y1)], [0, int(y0)]])\n",
    "    cv2.fillPoly(img_mask, pts=[points], color=0)\n",
    "    # erode to account for the pyrlk block size\n",
    "    erode_kernel = np.ones((erode_size, erode_size), np.uint8) \n",
    "    img_mask = cv2.erode(img_mask, erode_kernel)\n",
    "    return img_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show(*imgs):\n",
    "    for img in imgs:\n",
    "        plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_flow_mask():\n",
    "    erosion = 19\n",
    "    frame = 0\n",
    "    img_mask = get_full_flow_mask(frame, gimbal.get_frame(frame).shape, erosion)\n",
    "    show(img_mask)\n",
    "    \n",
    "if is_main: test_flow_mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test and run the cloud motion tracking algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "from dataclasses import dataclass\n",
    "\n",
    "num_frames = gimbal.get_frame_count()\n",
    "\n",
    "params_dict = {\n",
    "    'frame_diff_from': 6,\n",
    "    'frame_diff_to': 10,\n",
    "    'erosion': 19,\n",
    "    'min_mag': 1,\n",
    "    'gftt': {\n",
    "        'quality_level': 0.001,\n",
    "        'block_size': 5,\n",
    "        'min_dist': 0,\n",
    "    },\n",
    "    'pyrlk': {\n",
    "        'block_size': 31,\n",
    "        'max_level': 5,\n",
    "        'iters': 100\n",
    "    },\n",
    "    'affine': {\n",
    "        'threshold': 3,\n",
    "        'max_iters': 2000,\n",
    "        'confidence': 0.9999,\n",
    "        'refine_iters': 10\n",
    "    }\n",
    "}\n",
    "\n",
    "Params = utils.dict_to_obj(params_dict).__class__\n",
    "\n",
    "def get_frame_diff(frame, par:Params):\n",
    "    return int(par.frame_diff_from + frame * (par.frame_diff_to + 1 - par.frame_diff_from) / num_frames)\n",
    "\n",
    "def get_flow_roi(img):\n",
    "    return img[136:]\n",
    "def get_flow_roi_ofs():\n",
    "    return (136, 0)\n",
    "\n",
    "class CudaOpticalFlow:\n",
    "    def init_mats(self, *mats):\n",
    "        for mat in mats:\n",
    "            setattr(self, mat, cv2.cuda.GpuMat())\n",
    "    \n",
    "    def __init__(self, par:Params):\n",
    "        print(f'optical flow running on device {cv2.cuda.getDevice()}')\n",
    "        self.stream = cv2.cuda.Stream()\n",
    "        self.init_mats('gpu_img', 'gpu_mask', 'gpu_corners')\n",
    "        pg = par.gftt\n",
    "        self.cuda_gftt = cv2.cuda.createGoodFeaturesToTrackDetector(\n",
    "            cv2.CV_8UC1, 0, pg.quality_level, pg.min_dist, pg.block_size, False)\n",
    "        self.init_mats('gpu_img_next', 'gpu_corners_next')\n",
    "        self.init_mats('gpu_status', 'gpu_error')\n",
    "        pp = par.pyrlk\n",
    "        self.cuda_pyrlk = cv2.cuda.SparsePyrLKOpticalFlow.create(\n",
    "            (pp.block_size, pp.block_size), pp.max_level, pp.iters)\n",
    "    \n",
    "    def run(self, img, img_next, img_mask, par):\n",
    "        self.gpu_img.upload(img, self.stream)\n",
    "        self.gpu_img_next.upload(img_next, self.stream)\n",
    "        self.gpu_mask.upload(img_mask, self.stream)\n",
    "        self.gpu_corners = self.cuda_gftt.detect(self.gpu_img, self.gpu_corners, \n",
    "            self.gpu_mask, self.stream)\n",
    "        (self.gpu_corners_next, self.gpu_status, self.gpu_error) = self.cuda_pyrlk.calc(\n",
    "            self.gpu_img, self.gpu_img_next, self.gpu_corners,\n",
    "            self.gpu_corners_next, self.gpu_status, self.gpu_error, self.stream)\n",
    "        corners = self.gpu_corners.download(self.stream)[0]\n",
    "        corners_next = self.gpu_corners_next.download(self.stream)[0]\n",
    "        status = self.gpu_status.download(self.stream)[0]\n",
    "        self.stream.waitForCompletion()\n",
    "        return (corners, corners_next, status)\n",
    "\n",
    "class OpticalFlow:\n",
    "    def __init__(self, par:Params):\n",
    "        pp = par.pyrlk\n",
    "        self.pyrlk = cv2.SparsePyrLKOpticalFlow.create(\n",
    "            (pp.block_size, pp.block_size), pp.max_level)\n",
    "    \n",
    "    def run(self, img, img_next, img_mask, par: Params):\n",
    "        pg = par.gftt\n",
    "        corners = cv2.goodFeaturesToTrack(img, 0, pg.quality_level,\n",
    "            pg.min_dist, None, img_mask, pg.block_size, False)\n",
    "        (corners_next, status, error) = self.pyrlk.calc(\n",
    "            img, img_next, corners, None)\n",
    "        corners = np.reshape(corners, (len(corners), 2))\n",
    "        corners_next = np.reshape(corners_next, (len(corners_next), 2))\n",
    "        return (corners, corners_next, status)\n",
    "    \n",
    "def make_flow_algorithm(par:Params):\n",
    "    if use_opencv_cuda:\n",
    "        return CudaOpticalFlow(par)\n",
    "    else:\n",
    "        return OpticalFlow(par)\n",
    "\n",
    "@njit\n",
    "def filter_map_flow_results_jit(c1, c2, status, img_mask, ofs, min_mag, c1out, c2out):\n",
    "    (h,w) = img_mask.shape\n",
    "    (ofs_y,ofs_x) = ofs\n",
    "    def filter_map_status(i,j):\n",
    "        if status[i] == 0:\n",
    "            return (1,j)\n",
    "        (x1,y1) = c1[i]\n",
    "        (x2,y2) = c2[i]\n",
    "        if not (x2 >= 0 and y2 >= 0 and x2 < w and y2 < h):\n",
    "            return (2,j)\n",
    "        if img_mask[int(y2), int(x2)] != 255:\n",
    "            return (3,j)\n",
    "        (dx,dy) = (x2-x1,y2-y1)\n",
    "        mag = math.sqrt(dx*dx+dy*dy)\n",
    "        if mag < min_mag:\n",
    "            return (4,j)\n",
    "        c1out[j] = (x1+ofs_x, y1+ofs_y)\n",
    "        c2out[j] = (x2+ofs_x, y2+ofs_y)\n",
    "        return (0,j+1)\n",
    "    j = 0\n",
    "    for i in range(len(c1)):\n",
    "        (status[i],j) = filter_map_status(i,j)\n",
    "    return j\n",
    "\n",
    "#based on https://stackoverflow.com/questions/58422690/filtering-reducing-a-numpy-array\n",
    "def filter_map_flow_results(c1, c2, status, img_mask, min_mag):\n",
    "    ofs = get_flow_roi_ofs()\n",
    "    c1out = np.empty_like(c1)\n",
    "    c2out = np.empty_like(c2)\n",
    "    j = filter_map_flow_results_jit(c1, c2, status, img_mask, ofs, min_mag, c1out, c2out)\n",
    "    c1out.resize((j,2), refcheck=False)\n",
    "    c2out.resize((j,2), refcheck=False)\n",
    "    return (c1out, c2out, status)\n",
    "    \n",
    "def get_optical_flow(frame, frame_diff, par:Params, flow_algorithm):\n",
    "    next_frame = frame + frame_diff\n",
    "    if next_frame >= num_frames:\n",
    "        return ([],[],[])\n",
    "    (img, img_next) = [gimbal.get_frame(f) for f in [frame, next_frame]]\n",
    "    img_mask = get_full_flow_mask(frame, img.shape, par.erosion)\n",
    "    (img, img_next, img_mask) = [get_flow_roi(i) for i in [img, img_next, img_mask]]\n",
    "    (corners, corners_next, status) = flow_algorithm.run(img, img_next, img_mask, par)\n",
    "    return filter_map_flow_results(corners, corners_next, status, img_mask, par.min_mag)\n",
    "\n",
    "@njit\n",
    "def get_inlier_mean(corners, inliers):\n",
    "    (sum_x, sum_y, num_inliers) = (0.0, 0.0, 0)\n",
    "    # todo: does this need to be more numerically stable ?\n",
    "    for ((cx, cy), inlier) in zip(corners, inliers):\n",
    "        if inlier:\n",
    "            sum_x += float(cx); sum_y += float(cy)\n",
    "            num_inliers += 1\n",
    "    return np.array([sum_x / num_inliers, sum_y / num_inliers])\n",
    "\n",
    "@dataclass\n",
    "class CloudMotionData:\n",
    "    frame: int; frame_diff: int\n",
    "    magnitude: float; angle: float; rotation: float; transform: np.ndarray\n",
    "    corners: np.ndarray; corners_next: np.ndarray; status: np.ndarray; inliers: np.ndarray\n",
    "    c_inl_mean: float; cn_inl_mean: float\n",
    "\n",
    "def get_cloud_motion(frame, frame_diff, corners, corners_next, status, par: Params):\n",
    "    pa = par.affine\n",
    "    (transform, inliers) = cv2.estimateAffinePartial2D(corners, corners_next, None,\n",
    "        cv2.RANSAC, pa.threshold, pa.max_iters, pa.confidence, pa.refine_iters)\n",
    "    rotation = math.degrees(math.atan2(transform[1, 0], transform[0, 0]))\n",
    "    inliers = inliers.ravel() # from [[0],[1],...] to [0,1,...]\n",
    "    c_inl_mean = get_inlier_mean(corners, inliers)\n",
    "    cn_inl_mean = get_inlier_mean(corners_next, inliers)\n",
    "    mean = cn_inl_mean - c_inl_mean\n",
    "    magnitude = np.linalg.norm(mean) / frame_diff\n",
    "    angle = math.degrees(math.atan2(mean[1], mean[0]))\n",
    "    return CloudMotionData(frame, frame_diff,\n",
    "        magnitude, angle, rotation, transform,\n",
    "        corners, corners_next, status, inliers,\n",
    "        c_inl_mean, cn_inl_mean)\n",
    "\n",
    "def run_cloud_tracking_for(frames):\n",
    "    par = Params()\n",
    "    flow_algorithm = make_flow_algorithm(par)\n",
    "    motions = []\n",
    "    for frame in frames:\n",
    "        frame_diff = get_frame_diff(frame, par)\n",
    "        (corners, corners_next, status) = get_optical_flow(frame, frame_diff, par, flow_algorithm)\n",
    "        if len(corners) != 0:\n",
    "            motions.append(get_cloud_motion(frame, frame_diff, corners, corners_next, status, par))\n",
    "    return motions\n",
    "\n",
    "def get_cloud_frame_range():\n",
    "    if not use_opencv_cuda: # only do the last 1/10 the of the frames on the CPU\n",
    "        return range(num_frames - int(num_frames/10), num_frames)\n",
    "    return range(0, num_frames)\n",
    "\n",
    "def run_cloud_tracking():\n",
    "    return run_cloud_tracking_for(get_cloud_frame_range())\n",
    "\n",
    "def run_cloud_tracking_parallel():\n",
    "    return utils.run_jobs_in_parallel(work_func = run_cloud_tracking_for, \n",
    "        jobs = get_cloud_frame_range(), workers = 4, cv_cuda = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_flow(img, corners, corners_next, inliers):\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    for ((c1x,c1y), (c2x,c2y), inlier) in zip(corners, corners_next, inliers):\n",
    "        color = (0,255,0) if inlier else (255, 0, 0)\n",
    "        cv2.line(img_rgb, (int(c1x),int(c1y)), (int(c2x),int(c2y)), color, 1)\n",
    "    plt.imshow(img_rgb)\n",
    "    \n",
    "def test_flow():\n",
    "    par = Params()\n",
    "    flow = make_flow_algorithm(par)\n",
    "    frame = 980 #1000 # 5\n",
    "    frame_diff = get_frame_diff(frame, par)\n",
    "    (corners, corners_next, status) = get_optical_flow(frame, frame_diff, par, flow)\n",
    "    print(len(corners), len(corners_next))\n",
    "    m = get_cloud_motion(frame, frame_diff, corners, corners_next, status, par)\n",
    "    print(m.magnitude, m.angle, m.rotation)\n",
    "    show_flow(gimbal.get_frame(frame), corners, corners_next, m.inliers)\n",
    "    \n",
    "if is_main: test_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_main:\n",
    "    if use_opencv_cuda:\n",
    "        cloud_motions = %time run_cloud_tracking_parallel()\n",
    "    else: # the CPU version already uses multiple threads\n",
    "        cloud_motions = %time run_cloud_tracking()\n",
    "    print(len(cloud_motions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Plot the data and save it all to a parquet file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_main:\n",
    "    import pandas as pd\n",
    "    print(pd.__version__)\n",
    "    df_motion = pd.DataFrame.from_records([m.__dict__ for m in cloud_motions], index = [\"frame\"])\n",
    "    df_motion = df_motion.sort_index() # the parallel results are out of order\n",
    "    df_motion = common.gimbal_fix_wh_to_bh(df_motion, ['magnitude', 'angle', 'rotation'])\n",
    "    print(df_motion.dtypes)\n",
    "    df_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_motion(*fields):\n",
    "    plot_range = slice(df_motion.first_valid_index(), df_motion.last_valid_index())\n",
    "    for field in fields:\n",
    "        df_motion[field][plot_range].plot(legend = True)\n",
    "        plt.show()\n",
    "\n",
    "if is_main:\n",
    "    plot_motion('magnitude','rotation')\n",
    "    plt.ylim(bottom=13, top=50)\n",
    "    plot_motion('angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_main:\n",
    "    inlier_count = df_motion.inliers.map(lambda i : np.sum(i))\n",
    "    inlier_count[372-10:372] = np.nan\n",
    "    inlier_count.interpolate().plot(label = 'inlier count', legend = True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_flatten_ndarrays():\n",
    "    from IPython.display import display\n",
    "    (df_new, nd_shapes) = %time utils.flatten_ndarrays(df_motion)\n",
    "    df_old = %time utils.restore_ndarrays(df_new, nd_shapes)\n",
    "    display(df_new)\n",
    "    print(nd_shapes)\n",
    "    assert(df_motion.equals(df_old) == True)\n",
    "if is_main: test_flatten_ndarrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_main:\n",
    "    metadata = {\n",
    "        'params': params_dict\n",
    "    }\n",
    "    utils.to_parquet_ext(df_motion, 'cloud_motion.parquet', 'clouds', metadata)\n",
    "    !du -hs cloud_motion.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_main: utils.upload_to_huggingface('cloud_motion.parquet', 'logicbear/gimbal_clouds/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Save the corner means for a range of frame_diffs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cloud_tracking_means_for(frames):\n",
    "    par = Params()\n",
    "    flow_algorithm = make_flow_algorithm(par)\n",
    "    motions = []\n",
    "    for frame in frames:\n",
    "        fd_from = int(2 + frame * (4 + 1 - 2) / num_frames)\n",
    "        fd_to = fd_from + 10\n",
    "        for frame_diff in range(fd_from, fd_to + 1):\n",
    "            (corners, corners_next, status) = get_optical_flow(frame, frame_diff, par, flow_algorithm)\n",
    "            if len(corners) != 0:\n",
    "                motion = get_cloud_motion(frame, frame_diff, corners, corners_next, status, par)\n",
    "                for attr in ['corners','corners_next','status','inliers']:\n",
    "                    setattr(motion, attr, None)\n",
    "                motions.append(motion)\n",
    "    return motions\n",
    "\n",
    "if is_main:\n",
    "    ffds = [(m.frame, m.frame_diff) for m in run_cloud_tracking_means_for([0,1015,1025])]\n",
    "    print(ffds)\n",
    "\n",
    "def run_cloud_tracking_means():\n",
    "    cloud_means = utils.run_jobs_in_parallel(work_func = run_cloud_tracking_means_for, \n",
    "        jobs = get_cloud_frame_range(), workers = 4, cv_cuda = True)\n",
    "    df_means = pd.DataFrame.from_records([m.__dict__ for m in cloud_means],\n",
    "        index = ['frame','frame_diff'],\n",
    "        exclude = ['corners','corners_next','status','inliers'])\n",
    "    print(df_means.dtypes)\n",
    "    from IPython.display import display\n",
    "    display(df_means)\n",
    "    metadata = {\n",
    "        'params': params_dict\n",
    "    }\n",
    "    utils.to_parquet_ext(df_means, 'cloud_means.parquet', 'clouds', metadata)\n",
    "    !du -hs cloud_means.parquet\n",
    "    utils.upload_to_huggingface('cloud_means.parquet', 'logicbear/gimbal_cloud_means/data')\n",
    "    \n",
    "if is_main:\n",
    "    %time run_cloud_tracking_means()\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
